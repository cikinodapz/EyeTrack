{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbf1582-ea4c-416c-9082-0b326843c470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] Best scaler: robust | Acc: 0.7525 | AUC: 0.8318447845804988 | thr=0.498\n",
      "\n",
      "========== TEST ==========\n",
      "Best threshold: 0.498\n",
      "Accuracy: 0.7514\n",
      "ROC AUC : 0.8337\n",
      "Confusion matrix [[TN, FP], [FN, TP]]:\n",
      "[[18606  6426]\n",
      " [ 6019 19013]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Sequential(1)     0.7556    0.7433    0.7494     25032\n",
      "    Random(2)     0.7474    0.7595    0.7534     25032\n",
      "\n",
      "     accuracy                         0.7514     50064\n",
      "    macro avg     0.7515    0.7514    0.7514     50064\n",
      " weighted avg     0.7515    0.7514    0.7514     50064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgb_rowlevel_push74.py\n",
    "# Row-level XGBoost, fitur makin kaya:\n",
    "# - rolling variability (x,y,step) + circular stats (cos/sin Δangle, MRL, circular variance)\n",
    "# - entropy Δangle & step\n",
    "# - histogram fitur (Δangle 8 bin, step kuantil global 8–9 bin) -> nilai & proporsi\n",
    "# - rasio small/large saccade, rate langkah besar\n",
    "# - rolling quantiles & straightness, bbox\n",
    "# - auto-scaler selection (none/standard/robust/quantile)\n",
    "# NOTE: kompatibel XGBoost lama (tanpa early stopping / callbacks)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "CSV_PATH = \"truncated_dataset-seqglo.csv\"  # ganti kalau perlu\n",
    "ROLL_W = 21                # coba 15/21/25\n",
    "USE_SUBSAMPLE = True       # False = full training (lebih lama, bisa >1–2% naik)\n",
    "SUBSAMPLE_N = 140_000      # total train rows (imbang). Naikin jika kuat.\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "SCALE_MODES = [\"none\", \"standard\", \"robust\", \"quantile\"]\n",
    "\n",
    "XGB_KW = dict(\n",
    "    objective=\"binary:logistic\",\n",
    "    n_estimators=750,      # 650–900 (kalau dinaikkan, turunkan lr)\n",
    "    learning_rate=0.055,   # 0.05–0.07\n",
    "    max_depth=5,\n",
    "    min_child_weight=8,\n",
    "    gamma=0.25,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    reg_alpha=0.6,\n",
    "    reg_lambda=2.2,\n",
    "    tree_method=\"hist\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Utils\n",
    "# =========================\n",
    "def entropy_hist(a, bins_edges):\n",
    "    a = np.asarray(a)\n",
    "    a = a[np.isfinite(a)]\n",
    "    if a.size == 0:\n",
    "        return 0.0\n",
    "    hist, _ = np.histogram(a, bins=bins_edges)\n",
    "    s = hist.sum()\n",
    "    if s == 0:\n",
    "        return 0.0\n",
    "    p = hist.astype(float) / s\n",
    "    p = p[p > 0]\n",
    "    return float(-(p * np.log(p)).sum())\n",
    "\n",
    "def hist_feats(a, bins_edges, prefix):\n",
    "    \"\"\"Return dict: counts, proportions for each bin (except last edge), plus sum.\"\"\"\n",
    "    hist, _ = np.histogram(a, bins=bins_edges)\n",
    "    total = hist.sum() + 1e-9\n",
    "    d = {}\n",
    "    for i, c in enumerate(hist):\n",
    "        d[f\"{prefix}_bin{i}\"] = float(c)\n",
    "        d[f\"{prefix}_p{i}\"] = float(c) / total\n",
    "    d[f\"{prefix}_sum\"] = float(total)\n",
    "    return d\n",
    "\n",
    "# =========================\n",
    "# 1) Load & pre-bins (global)\n",
    "# =========================\n",
    "df = pd.read_csv(CSV_PATH).sort_values([\"nama\", \"time\"]).reset_index(drop=True)\n",
    "\n",
    "# global deltas untuk bikin step bins stabil\n",
    "dx_all = df[\"gazeX\"].diff()\n",
    "dy_all = df[\"gazeY\"].diff()\n",
    "mask_new_subject = df[\"nama\"].ne(df[\"nama\"].shift(1))\n",
    "dx_all = dx_all.mask(mask_new_subject, 0.0)\n",
    "dy_all = dy_all.mask(mask_new_subject, 0.0)\n",
    "step_all = np.sqrt(dx_all**2 + dy_all**2).fillna(0.0).values\n",
    "\n",
    "# kuantil global untuk step bins (8–9 bin)\n",
    "q = np.quantile(step_all, [0.00, 0.10, 0.25, 0.50, 0.75, 0.90, 0.97, 0.995, 1.00])\n",
    "step_bins = np.unique(q)\n",
    "if step_bins.size < 6:\n",
    "    step_bins = np.linspace(float(step_all.min()), float(step_all.max()+1e-6), 9)\n",
    "\n",
    "# delta-angle bins (8 bin rata di [-pi, pi])\n",
    "dang_bins = np.linspace(-np.pi, np.pi, 9)\n",
    "\n",
    "# threshold small/large saccade (pakai kuantil global)\n",
    "small_thr = np.quantile(step_all, 0.25)  # saccade kecil\n",
    "large_thr = np.quantile(step_all, 0.90)  # saccade besar\n",
    "\n",
    "# =========================\n",
    "# 2) Feature Engineering\n",
    "# =========================\n",
    "def add_roll_feats(g, w=21):\n",
    "    g = g.copy()\n",
    "\n",
    "    dx = g[\"gazeX\"].diff()\n",
    "    dy = g[\"gazeY\"].diff()\n",
    "    dx.iloc[0] = 0.0; dy.iloc[0] = 0.0\n",
    "    step = np.sqrt(dx**2 + dy**2)\n",
    "\n",
    "    ang = np.arctan2(dy, dx)\n",
    "    d_ang = np.diff(ang, prepend=ang.iloc[0])\n",
    "    d_ang = (d_ang + np.pi) % (2*np.pi) - np.pi\n",
    "\n",
    "    # circular stats (rolling)\n",
    "    cos_da = np.cos(d_ang)\n",
    "    sin_da = np.sin(d_ang)\n",
    "    r_mean_cos = pd.Series(cos_da, index=g.index).rolling(w, min_periods=1).mean()\n",
    "    r_mean_sin = pd.Series(sin_da, index=g.index).rolling(w, min_periods=1).mean()\n",
    "    r_mrl = np.sqrt(r_mean_cos**2 + r_mean_sin**2)\n",
    "    r_circ_var = 1.0 - r_mrl\n",
    "\n",
    "    # rolling basic stats\n",
    "    g[\"r_std_x\"] = g[\"gazeX\"].rolling(w, min_periods=1).std()\n",
    "    g[\"r_std_y\"] = g[\"gazeY\"].rolling(w, min_periods=1).std()\n",
    "    g[\"r_mean_step\"] = step.rolling(w, min_periods=1).mean()\n",
    "    g[\"r_std_step\"]  = step.rolling(w, min_periods=1).std()\n",
    "    g[\"r_mean_abs_dang\"] = pd.Series(np.abs(d_ang), index=g.index).rolling(w, min_periods=1).mean()\n",
    "    g[\"r_std_dang\"] = pd.Series(d_ang, index=g.index).rolling(w, min_periods=1).std()\n",
    "    try:\n",
    "        g[\"r_skew_step\"] = pd.Series(step, index=g.index).rolling(w, min_periods=1).skew()\n",
    "        g[\"r_kurt_step\"] = pd.Series(step, index=g.index).rolling(w, min_periods=1).kurt()\n",
    "    except Exception:\n",
    "        g[\"r_skew_step\"] = 0.0\n",
    "        g[\"r_kurt_step\"] = 0.0\n",
    "\n",
    "    # rolling quantiles\n",
    "    g[\"r_q25_step\"] = pd.Series(step, index=g.index).rolling(w, min_periods=1).quantile(0.25)\n",
    "    g[\"r_q75_step\"] = pd.Series(step, index=g.index).rolling(w, min_periods=1).quantile(0.75)\n",
    "\n",
    "    # straightness & bbox\n",
    "    disp_x = g[\"gazeX\"] - g[\"gazeX\"].shift(w-1)\n",
    "    disp_y = g[\"gazeY\"] - g[\"gazeY\"].shift(w-1)\n",
    "    disp = np.sqrt(disp_x**2 + disp_y**2)\n",
    "    path_w = pd.Series(step, index=g.index).rolling(w, min_periods=1).sum() + 1e-6\n",
    "    g[\"r_straight_ratio\"] = (disp / path_w).fillna(0)\n",
    "    g[\"bbox_w\"] = g[\"gazeX\"].rolling(w, min_periods=1).max() - g[\"gazeX\"].rolling(w, min_periods=1).min()\n",
    "    g[\"bbox_h\"] = g[\"gazeY\"].rolling(w, min_periods=1).max() - g[\"gazeY\"].rolling(w, min_periods=1).min()\n",
    "\n",
    "    # entropy (rolling)\n",
    "    g[\"r_entropy_dang\"] = pd.Series(d_ang, index=g.index).rolling(w, min_periods=1).apply(\n",
    "        lambda a: entropy_hist(a, dang_bins), raw=True\n",
    "    )\n",
    "    g[\"r_entropy_step\"] = pd.Series(step, index=g.index).rolling(w, min_periods=1).apply(\n",
    "        lambda a: entropy_hist(a, step_bins), raw=True\n",
    "    )\n",
    "\n",
    "    # histogram features (rolling) – gunakan pusat window (i) ambil range i-w+1..i\n",
    "    # untuk efisiensi, pakai rolling apply raw dan kembalikan statistik ringkas:\n",
    "    def roll_hist_features(series, bins, pref):\n",
    "        # apply mengembalikan satu angka, jadi kita bikin beberapa kali untuk each bin/prop → mahal.\n",
    "        # Alternatif: hitung di akhir per-baris (lebih simpel, sedikit lebih lambat tapi oke).\n",
    "        arr = []\n",
    "        s = series.values\n",
    "        n = len(s)\n",
    "        for i in range(n):\n",
    "            i0 = max(0, i - w + 1)\n",
    "            win = s[i0:i+1]\n",
    "            d = hist_feats(win, bins, pref)\n",
    "            arr.append(d)\n",
    "        return pd.DataFrame(arr, index=series.index)\n",
    "\n",
    "    # Δangle histogram\n",
    "    dang_hist_df = roll_hist_features(pd.Series(d_ang, index=g.index), dang_bins, \"h_dang\")\n",
    "    # step histogram\n",
    "    step_hist_df = roll_hist_features(pd.Series(step, index=g.index), step_bins, \"h_step\")\n",
    "\n",
    "    # gabung ke g\n",
    "    g = pd.concat([g, dang_hist_df, step_hist_df], axis=1)\n",
    "\n",
    "    # small/large saccade ratios & rates\n",
    "    small_mask = (step <= small_thr).astype(float)\n",
    "    large_mask = (step >= large_thr).astype(float)\n",
    "    g[\"r_rate_small\"] = pd.Series(small_mask, index=g.index).rolling(w, min_periods=1).mean()\n",
    "    g[\"r_rate_large\"] = pd.Series(large_mask, index=g.index).rolling(w, min_periods=1).mean()\n",
    "    g[\"r_ratio_small_large\"] = (g[\"r_rate_small\"] / (g[\"r_rate_large\"] + 1e-6)).replace([np.inf, -np.inf], 0.0)\n",
    "\n",
    "    # base deltas\n",
    "    g[\"dx\"] = dx\n",
    "    g[\"dy\"] = dy\n",
    "    g[\"abs_dx\"] = dx.abs()\n",
    "    g[\"abs_dy\"] = dy.abs()\n",
    "    g[\"step\"] = step\n",
    "\n",
    "    # circular bundle\n",
    "    g[\"r_mean_cos_dang\"] = r_mean_cos\n",
    "    g[\"r_mean_sin_dang\"] = r_mean_sin\n",
    "    g[\"r_mrl_dang\"] = r_mrl\n",
    "    g[\"r_circvar_dang\"] = r_circ_var\n",
    "\n",
    "    return g\n",
    "\n",
    "# compat include_groups\n",
    "try:\n",
    "    df = df.groupby(\"nama\", group_keys=False).apply(add_roll_feats, include_groups=False, w=ROLL_W)\n",
    "except TypeError:\n",
    "    df = df.groupby(\"nama\", group_keys=False).apply(add_roll_feats, w=ROLL_W)\n",
    "\n",
    "# bersihin NaN/Inf\n",
    "for col in df.columns:\n",
    "    if col in [\"nama\", \"time\", \"gazeX\", \"gazeY\", \"label\"]:\n",
    "        continue\n",
    "    med = pd.to_numeric(df[col], errors=\"coerce\").replace([np.inf, -np.inf], np.nan).median()\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\").replace([np.inf, -np.inf], np.nan).fillna(med)\n",
    "\n",
    "# =========================\n",
    "# 3) Features & Label\n",
    "# =========================\n",
    "# pilih semua kolom numerik kecuali yang dilarang\n",
    "exclude = {\"nama\", \"label\"}\n",
    "feature_cols = [c for c in df.columns if c not in exclude]\n",
    "X = df[feature_cols].astype(float).copy()\n",
    "y = (df[\"label\"] == 2).astype(int).values\n",
    "\n",
    "# =========================\n",
    "# 4) Split\n",
    "# =========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# subsample train imbang (opsional)\n",
    "if USE_SUBSAMPLE:\n",
    "    rng = np.random.RandomState(RANDOM_STATE)\n",
    "    ix_pos = np.where(y_train == 1)[0]\n",
    "    ix_neg = np.where(y_train == 0)[0]\n",
    "    n_each = min(SUBSAMPLE_N // 2, len(ix_pos), len(ix_neg))\n",
    "    sel = np.concatenate([\n",
    "        rng.choice(ix_pos, n_each, replace=False),\n",
    "        rng.choice(ix_neg, n_each, replace=False),\n",
    "    ])\n",
    "    X_train_small = X_train.iloc[sel].reset_index(drop=True)\n",
    "    y_train_small = y_train[sel]\n",
    "else:\n",
    "    X_train_small = X_train.reset_index(drop=True)\n",
    "    y_train_small = y_train\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_small, y_train_small, test_size=0.15, stratify=y_train_small, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 5) Scaler selection\n",
    "# =========================\n",
    "def fit_transform_scaler(mode, Xtr, Xva):\n",
    "    if mode == \"none\":\n",
    "        return Xtr.values, Xva.values, None\n",
    "    elif mode == \"standard\":\n",
    "        sc = StandardScaler()\n",
    "    elif mode == \"robust\":\n",
    "        sc = RobustScaler()\n",
    "    elif mode == \"quantile\":\n",
    "        sc = QuantileTransformer(output_distribution=\"normal\", random_state=RANDOM_STATE, subsample=300_000)\n",
    "    else:\n",
    "        raise ValueError(\"unknown scaler\")\n",
    "    Xtr_s = sc.fit_transform(Xtr)\n",
    "    Xva_s = sc.transform(Xva)\n",
    "    return Xtr_s, Xva_s, sc\n",
    "\n",
    "best = dict(mode=None, thr=0.5, acc=-1.0, auc=None, model=None, scaler=None)\n",
    "for mode in SCALE_MODES:\n",
    "    Xtr_s, Xva_s, scaler = fit_transform_scaler(mode, X_tr, X_val)\n",
    "    clf = XGBClassifier(**XGB_KW)\n",
    "    clf.fit(Xtr_s, y_tr)\n",
    "\n",
    "    proba_val = clf.predict_proba(Xva_s)[:, 1]\n",
    "    # grid rapat sekitar 0.5\n",
    "    ths = np.arange(0.40, 0.601, 0.0015)\n",
    "    local_best_acc, local_best_thr = -1.0, 0.5\n",
    "    for t in ths:\n",
    "        acc_val = accuracy_score(y_val, (proba_val >= t).astype(int))\n",
    "        if acc_val > local_best_acc:\n",
    "            local_best_acc, local_best_thr = acc_val, float(t)\n",
    "\n",
    "    try:\n",
    "        auc_val = roc_auc_score(y_val, proba_val)\n",
    "    except Exception:\n",
    "        auc_val = None\n",
    "\n",
    "    if local_best_acc > best[\"acc\"]:\n",
    "        best.update(dict(mode=mode, thr=local_best_thr, acc=local_best_acc, auc=auc_val, model=clf, scaler=scaler))\n",
    "\n",
    "print(f\"[VAL] Best scaler: {best['mode']} | Acc: {best['acc']:.4f} | AUC: {best['auc'] if best['auc'] is not None else 'nan'} | thr={best['thr']:.3f}\")\n",
    "\n",
    "def apply_scaler(scaler, X):\n",
    "    return X.values if scaler is None else scaler.transform(X)\n",
    "\n",
    "# =========================\n",
    "# 6) Test eval\n",
    "# =========================\n",
    "X_test_s = apply_scaler(best[\"scaler\"], X_test)\n",
    "proba_test = best[\"model\"].predict_proba(X_test_s)[:, 1]\n",
    "preds_test = (proba_test >= best[\"thr\"]).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, preds_test)\n",
    "try:\n",
    "    auc = roc_auc_score(y_test, proba_test)\n",
    "except Exception:\n",
    "    auc = float(\"nan\")\n",
    "cm = confusion_matrix(y_test, preds_test)\n",
    "report = classification_report(y_test, preds_test, target_names=[\"Sequential(1)\",\"Random(2)\"], digits=4)\n",
    "\n",
    "print(\"\\n========== TEST ==========\")\n",
    "print(f\"Best threshold: {best['thr']:.3f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"ROC AUC : {auc:.4f}\")\n",
    "print(\"Confusion matrix [[TN, FP], [FN, TP]]:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification report:\")\n",
    "print(report)\n",
    "\n",
    "# (opsional) simpan model\n",
    "# from pathlib import Path\n",
    "# best[\"model\"].get_booster().save_model(\"xgb_rowlevel_push74.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8443c49-119c-4e1b-bc10-5cf83c06f7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
